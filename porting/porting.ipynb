{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622e4b13-e384-4c01-bf48-5a02fccb131a",
   "metadata": {},
   "source": [
    "# Pytorch -> ONNX -> TFLite\n",
    "\n",
    "pytorch에서 TFLite까지 변환하는 것을 목표로 하는 Notebook입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9856fd9-f4ac-483d-8c25-3edddd9466cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from torchsummary import summary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf589e7-1bed-40d4-8ce9-e3a38e5e7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df007331-50c7-4c5a-a25a-15abf516d998",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523be336-bd8a-40b2-b800-dae35ffab40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/opt/ml/final_project/kyh/model/'\n",
    "\n",
    "# model1. deeplabv3(backbone:mobileNetV3-large) 모델에 용범님이 올려주신 deeplabV3 pth 파일 weight 씌움\n",
    "model_path = os.path.join(model_dir, 'deeplabv3_mobilenet_v3_large_sample.pth')\n",
    "model_pt = torch.load(model_path)\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True).to(device)\n",
    "model.load_state_dict(model_pt)\n",
    "\n",
    "# model2. ONNX tutorial 예시 모델인 torchvision Alexnet\n",
    "model2 = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "\n",
    "model.eval()\n",
    "model2.eval()\n",
    "\n",
    "#summary(model, input_size=(3,960,720))\n",
    "#print(model)\n",
    "#print(type(model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9ff31-a3f3-4161-831a-c887c770e26b",
   "metadata": {},
   "source": [
    "## Model -> ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4bf61-1f01-4457-b8f3-69fd815bb8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "dummy_input = torch.zeros(batch_size, 3, 960, 720).to(device)\n",
    "\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "# 'f' 파라미터로 파일 이름 맞추는 거 잊지말기\n",
    "torch.onnx.export(model, dummy_input, f='sample_onnx_model.onnx', verbose=False, input_names=input_names, output_names=output_names,\n",
    "                 operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9ec26-1199-4706-b10b-13d5c14fd2c9",
   "metadata": {},
   "source": [
    "## ONNX 빌드 잘 되었는지 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ddc8be-0447-4f47-b947-41dd54d31d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"/opt/ml/final_project/kyh/sample_onnx_model.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a Human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27928f-21a0-422f-9246-eb8fa3c87290",
   "metadata": {},
   "source": [
    "## ONNX 파일 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25c919-37b1-418b-8f34-41ac4b699588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(\"/opt/ml/final_project/kyh/sample_onnx_model.onnx\")\n",
    "\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {'actual_input_1': np.random.randn(batch_size, 3, 960, 720).astype(np.float32)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603c538-f414-4fc9-9285-69836bce2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936ef1f-06d8-4f04-a912-1ef6730cc32b",
   "metadata": {},
   "source": [
    "## ONNX -> Tensorflow 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be84b06-0b6a-4897-9112-d40731336f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./onnx-tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d8057-8e55-4b04-8c51-22aa1b2eb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tensorflow as tf\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model_path = \"/opt/ml/final_project/kyh/sample_onnx_model.onnx\"\n",
    "tf_model_path = \"/opt/ml/final_project/kyh/tf_model\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "tf_rep = prepare(onnx_model)\n",
    "\n",
    "tf_rep.export_graph(tf_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9e558-8b0a-485e-b301-d174c2a40c79",
   "metadata": {},
   "source": [
    "## Tensorflow Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9edb74-64fc-4c2b-b4f4-df5b02f3b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(tf_model_path)\n",
    "model.trainable = False\n",
    "\n",
    "input_tensor = tf.random.uniform([8, 3, 960, 720])\n",
    "out = model(**{'actual_input_1': input_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95006fc2-2b51-4683-ae90-618126a735da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833cfb3-8b9f-469b-97d6-4ca2ad3acecb",
   "metadata": {},
   "source": [
    "## Tensorflow -> TFLite 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9c367-1540-485f-845a-32f86384e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_path = \"/opt/ml/final_project/kyh/tflite_model/tflite_model.tflite\"\n",
    "\n",
    "# Save the model\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9e5bc-2b07-4216-9bf8-e5da48037f05",
   "metadata": {},
   "source": [
    "## TFLite Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02911b-d65e-42aa-b297-3309c1625322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"/opt/ml/final_project/kyh/tflite_model/tflite_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# get_tensor() returns a copy of the tensor data\n",
    "# use tensor() in order to get a pointer to the tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
