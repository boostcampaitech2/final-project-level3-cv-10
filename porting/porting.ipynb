{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conda 환경 설정\n",
    "!conda create -n convert\n",
    "!conda activate convert\n",
    "!conda install jupyter notebook\n",
    "!python3 -m ipykernel install --user --name convert --display-name \"convert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update\n",
    "!sudo apt update --yes\n",
    "!sudo apt upgrade --yes\n",
    "!sudo apt autoremove --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib 설치\n",
    "!conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "!conda install -c conda-forge onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ai/Desktop/work/ai_boostcamp/final/pth_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch를 ONNX로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "#https://github.com/pytorch/vision/blob/main/torchvision/models/segmentation/deeplabv3.py\n",
    "\n",
    "#customized model\n",
    "from models.deeplabv3 import deeplabv3_mobilenet_v3\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch_model = deeplabv3_mobilenet_v3(\n",
    "    pretrained_backbone=False,\n",
    "    aux_loss=False,\n",
    "    small=True,\n",
    "    reduced_tail=True,\n",
    "    grid_mode=True,\n",
    ").to(device)\n",
    "\n",
    "model_path = './dlv3_mbv3-small_reduced_grid.211222.pth'\n",
    "tmp = torch.load(model_path)\n",
    "for w_name in list(tmp.keys())[-8:]:\n",
    "    del tmp[w_name]\n",
    "torch_model.load_state_dict(tmp)\n",
    "\n",
    "torch_model.eval()\n",
    "\n",
    "batch_size = 1\n",
    "x = torch.randn(batch_size, 3, 240, 320).to(device)\n",
    "\n",
    "torch.onnx.export(torch_model,\n",
    "                  x,\n",
    "                  \"onnx.onnx\",\n",
    "                  export_params=True,\n",
    "                  opset_version=10,\n",
    "                  do_constant_folding=True,\n",
    "                  verbose = True,\n",
    "                  input_names = ['actual_input_1'],\n",
    "                  output_names = ['output1']\n",
    "                  )\n",
    "onnx_model = onnx.load(\"onnx.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx.helper.printable_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX를 TensorFlow로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx_tf\n",
    "!sudo apt update --yes\n",
    "!sudo apt install python3-dev python3-pip python3-venv --yes\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "\n",
    "TF_PATH = \"./pb.pb\"\n",
    "ONNX_PATH = \"./onnx.onnx\"\n",
    "onnx_model = onnx.load(ONNX_PATH)\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(TF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow를 TensorFlow Lite로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./pb.pb\")\n",
    "\n",
    "#optimization\n",
    "#https://github.com/sithu31296/PyTorch-ONNX-TFLite\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#https://www.tensorflow.org/lite/performance/post_training_quantization?hl=ko\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('tflite.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = './test_images/MP_SEL_SUR_000004.jpg'\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((240, 320)),\n",
    "])\n",
    "input_data = preprocess(input_image)\n",
    "input_data = input_data.unsqueeze(0)\n",
    "\n",
    "print(input_data.size())\n",
    "interpreter = tf.lite.Interpreter(model_path='tflite.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data = output_data.argmax(1)\n",
    "input_data = input_data[0].cpu().numpy().transpose([1, 2, 0])\n",
    "print(input_data.shape)\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, dpi=200)\n",
    "axes[0].imshow(output_data[0])\n",
    "axes[1].imshow(input_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55558c5b5f3dd3c37f143c615d8e3fce0a754830491af7fc6afd8a1ca32d19c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('convert': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
