{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conda 환경 설정\n",
    "!conda create -n convert\n",
    "!conda activate convert\n",
    "!conda install jupyter notebook\n",
    "!python3 -m ipykernel install --user --name convert --display-name \"convert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update\n",
    "!sudo apt update --yes\n",
    "!sudo apt upgrade --yes\n",
    "#you make wanna run below command to remove unwanted\n",
    "#and free up some space\n",
    "!sudo apt autoremove --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib 설치\n",
    "!conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "!conda install -c conda-forge onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ai/Desktop/work/ai_boostcamp/final/pth_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch를 ONNX로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "#https://github.com/pytorch/vision/blob/main/torchvision/models/segmentation/deeplabv3.py\n",
    "#deeplabv3_mobilenet_v3_large_coco\": \"https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth\n",
    "torch_model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\n",
    "#model_path = './deeplabv3_mobilenet_v3_large-fc3c493d.pth'\n",
    "model_path = './model_weights.pth'\n",
    "torch_model.load_state_dict(torch.load(model_path))\n",
    "torch_model.eval()\n",
    "\n",
    "batch_size = 1\n",
    "#[batch_size, channels, height, width]\n",
    "x = torch.randn(batch_size, 3, 480, 640, requires_grad=True)\n",
    "torch_out = torch_model(x)\n",
    "\n",
    "# 모델 변환\n",
    "torch.onnx.export(torch_model,               # 실행될 모델\n",
    "                  x,                         # 모델 입력값 (튜플 또는 여러 입력값들도 가능)\n",
    "                  \"onnx.onnx\",   # 모델 저장 경로 (파일 또는 파일과 유사한 객체 모두 가능)\n",
    "                  #export_params=True,        # 모델 파일 안에 학습된 모델 가중치를 저장할지의 여부 default True\n",
    "                  opset_version=10,          # 모델을 변환할 때 사용할 ONNX 버전\n",
    "                  #do_constant_folding=False,  # 최적하시 상수폴딩을 사용할지의 여부 Default False\n",
    "                  input_names = ['input'],   # 모델의 입력값을 가리키는 이름\n",
    "                  output_names = ['output'] # 모델의 출력값을 가리키는 이름\n",
    "                  )\n",
    "onnx_model = onnx.load(\"onnx.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX를 TensorFlow로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx_tf\n",
    "!sudo apt update --yes\n",
    "!sudo apt install python3-dev python3-pip python3-venv --yes\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "\n",
    "TF_PATH = \"./pb.pb\" # where the representation of tensorflow model will be stored\n",
    "ONNX_PATH = \"./onnx.onnx\" # path to my existing ONNX model\n",
    "onnx_model = onnx.load(ONNX_PATH)  # load onnx model\n",
    "\n",
    "# prepare function converts an ONNX model to an internel representation\n",
    "# of the computational graph called TensorflowRep and returns\n",
    "# the converted representation.\n",
    "tf_rep = prepare(onnx_model)  # creating TensorflowRep object\n",
    "\n",
    "# export_graph function obtains the graph proto corresponding to the ONNX\n",
    "# model associated with the backend representation and serializes\n",
    "# to a protobuf file.\n",
    "tf_rep.export_graph(TF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow를 TensorFlow Lite로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./pb.pb\") # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('tflite.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55558c5b5f3dd3c37f143c615d8e3fce0a754830491af7fc6afd8a1ca32d19c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('convert': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
